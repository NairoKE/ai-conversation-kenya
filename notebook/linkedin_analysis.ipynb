{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# AI Conversation Analysis in Kenya: Insights & Visualizations\n",
        "\n",
        "This notebook analyzes AI and digital transformation discussions among Kenyan organizations and leaders, focusing on creating engaging visualizations and extracting noteworthy insights for LinkedIn sharing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Set style for visualizations\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Custom color palette for Kenya-themed visualizations\n",
        "kenya_colors = ['#BE0027', '#000000', '#169B62', '#FFFFFF']  # Colors from Kenyan flag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "def load_latest_data():\n",
        "    \"\"\"Load the most recent data file from the data directory\"\"\"\n",
        "    import glob\n",
        "    import os\n",
        "    \n",
        "    # Find the latest LinkedIn data file\n",
        "    files = glob.glob('../data/linkedin_posts_*.csv')\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No LinkedIn data files found\")\n",
        "    \n",
        "    latest_file = max(files, key=os.path.getctime)\n",
        "    df = pd.read_csv(latest_file)\n",
        "    \n",
        "    # Convert date column\n",
        "    df['post_date'] = pd.to_datetime(df['timestamp'])\n",
        "    \n",
        "    # Clean text data\n",
        "    df['clean_content'] = df['content'].apply(clean_text)\n",
        "    \n",
        "    # Extract company size categories\n",
        "    df['company_size_cat'] = pd.Categorical(df['company_size'], \n",
        "                                          categories=['Small (<50)', 'Medium (50-500)', 'Large (>500)'],\n",
        "                                          ordered=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text data\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    \n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Load the data\n",
        "try:\n",
        "    df = load_latest_data()\n",
        "    print(f\"Loaded {len(df)} posts\")\n",
        "    print(\"\\nData Overview:\")\n",
        "    print(df.info())\n",
        "except FileNotFoundError as e:\n",
        "    print(\"Warning: Data files not found. Please run the scraper first.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. AI Conversation Leaders in Kenya\n",
        "\n",
        "Let's identify and visualize the organizations and individuals leading the AI conversation in Kenya.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze organization engagement\n",
        "def analyze_top_organizations():\n",
        "    # Calculate engagement metrics\n",
        "    df['engagement_score'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3\n",
        "    \n",
        "    # Aggregate by company\n",
        "    company_stats = df.groupby('company').agg({\n",
        "        'engagement_score': ['sum', 'mean'],\n",
        "        'post_date': 'count',\n",
        "        'likes': 'sum',\n",
        "        'comments': 'sum',\n",
        "        'shares': 'sum'\n",
        "    }).round(2)\n",
        "    \n",
        "    company_stats.columns = ['total_engagement', 'avg_engagement', 'post_count', \n",
        "                           'total_likes', 'total_comments', 'total_shares']\n",
        "    \n",
        "    # Sort by total engagement\n",
        "    company_stats = company_stats.sort_values('total_engagement', ascending=False)\n",
        "    \n",
        "    return company_stats\n",
        "\n",
        "# Create visualization of top organizations\n",
        "def plot_top_organizations(stats, top_n=10):\n",
        "    # Prepare data for plotting\n",
        "    plot_data = stats.head(top_n)\n",
        "    \n",
        "    # Create interactive bar chart using Plotly\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # Add bars for different metrics\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=plot_data.index,\n",
        "        y=plot_data['total_likes'],\n",
        "        name='Likes',\n",
        "        marker_color=kenya_colors[0]\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        x=plot_data.index,\n",
        "        y=plot_data['total_comments'],\n",
        "        name='Comments',\n",
        "        marker_color=kenya_colors[2]\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "        x=plot_data.index,\n",
        "        y=plot_data['total_shares'],\n",
        "        name='Shares',\n",
        "        marker_color=kenya_colors[1]\n",
        "    ))\n",
        "    \n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title='Top Organizations Leading AI Conversations in Kenya',\n",
        "        xaxis_title='Organization',\n",
        "        yaxis_title='Engagement Metrics',\n",
        "        barmode='stack',\n",
        "        showlegend=True,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Generate insights\n",
        "org_stats = analyze_top_organizations()\n",
        "print(\"Top 5 Organizations by Engagement:\")\n",
        "print(org_stats[['total_engagement', 'post_count', 'avg_engagement']].head().to_string())\n",
        "\n",
        "# Create and display visualization\n",
        "fig = plot_top_organizations(org_stats)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze topics and create trend visualization\n",
        "def analyze_topics():\n",
        "    # Create custom stopwords\n",
        "    custom_stopwords = set(stopwords.words('english') + ['ai', 'artificial', 'intelligence', 'kenya', 'kenyan'])\n",
        "    \n",
        "    # Extract and count keywords\n",
        "    all_words = ' '.join(df['clean_content'].dropna())\n",
        "    words = word_tokenize(all_words)\n",
        "    words = [word for word in words if word.lower() not in custom_stopwords and len(word) > 2]\n",
        "    \n",
        "    # Count word frequencies\n",
        "    word_freq = Counter(words)\n",
        "    top_words = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:50])\n",
        "    \n",
        "    return top_words\n",
        "\n",
        "# Generate word cloud visualization\n",
        "def create_topic_wordcloud(word_freq):\n",
        "    wordcloud = WordCloud(\n",
        "        width=1200, \n",
        "        height=800,\n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        max_words=100\n",
        "    ).generate_from_frequencies(word_freq)\n",
        "    \n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Most Discussed AI Topics in Kenya', pad=20, size=16)\n",
        "    plt.tight_layout(pad=0)\n",
        "    \n",
        "    return plt\n",
        "\n",
        "# Plot monthly trends\n",
        "def plot_topic_trends():\n",
        "    df['month'] = df['post_date'].dt.to_period('M')\n",
        "    monthly_posts = df.groupby('month').size()\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=monthly_posts.index.astype(str),\n",
        "        y=monthly_posts.values,\n",
        "        mode='lines+markers',\n",
        "        name='Posts',\n",
        "        line=dict(color=kenya_colors[2], width=3),\n",
        "        marker=dict(size=8)\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='AI Discussion Trends Over Time',\n",
        "        xaxis_title='Month',\n",
        "        yaxis_title='Number of Posts',\n",
        "        template='plotly_white',\n",
        "        showlegend=False\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Generate insights and visualizations\n",
        "word_freq = analyze_topics()\n",
        "print(\"Top 10 Most Discussed Topics:\")\n",
        "for word, freq in list(word_freq.items())[:10]:\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "# Display visualizations\n",
        "create_topic_wordcloud(word_freq)\n",
        "plt.show()\n",
        "\n",
        "trend_fig = plot_topic_trends()\n",
        "trend_fig.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Seniority Analysis and Industry Impact\n",
        "\n",
        "Understanding how different organizational levels are contributing to the AI conversation and which industries are leading the transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze seniority distribution and impact\n",
        "def analyze_seniority():\n",
        "    # Calculate engagement by seniority\n",
        "    seniority_stats = df.groupby('seniority_level').agg({\n",
        "        'engagement_score': ['mean', 'sum'],\n",
        "        'post_date': 'count'\n",
        "    }).round(2)\n",
        "    \n",
        "    seniority_stats.columns = ['avg_engagement', 'total_engagement', 'post_count']\n",
        "    return seniority_stats\n",
        "\n",
        "def plot_seniority_insights():\n",
        "    # Create sunburst chart for seniority and company size\n",
        "    sunburst_data = df.groupby(['seniority_level', 'company_size_cat'])['engagement_score'].sum().reset_index()\n",
        "    \n",
        "    fig = px.sunburst(\n",
        "        sunburst_data,\n",
        "        path=['seniority_level', 'company_size_cat'],\n",
        "        values='engagement_score',\n",
        "        color='seniority_level',\n",
        "        color_discrete_sequence=px.colors.qualitative.Set3,\n",
        "        title='AI Discussion Distribution by Seniority and Company Size'\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        width=800,\n",
        "        height=800,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def plot_engagement_by_seniority():\n",
        "    # Calculate average engagement metrics by seniority\n",
        "    engagement_metrics = df.groupby('seniority_level').agg({\n",
        "        'likes': 'mean',\n",
        "        'comments': 'mean',\n",
        "        'shares': 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    # Create grouped bar chart\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    metrics = ['likes', 'comments', 'shares']\n",
        "    colors = kenya_colors[:3]\n",
        "    \n",
        "    for metric, color in zip(metrics, colors):\n",
        "        fig.add_trace(go.Bar(\n",
        "            name=metric.capitalize(),\n",
        "            x=engagement_metrics.index,\n",
        "            y=engagement_metrics[metric],\n",
        "            marker_color=color\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='Average Engagement by Seniority Level',\n",
        "        xaxis_title='Seniority Level',\n",
        "        yaxis_title='Average Engagement',\n",
        "        barmode='group',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Generate insights\n",
        "seniority_stats = analyze_seniority()\n",
        "print(\"Engagement by Seniority Level:\")\n",
        "print(seniority_stats)\n",
        "\n",
        "# Create and display visualizations\n",
        "sunburst_fig = plot_seniority_insights()\n",
        "sunburst_fig.show()\n",
        "\n",
        "engagement_fig = plot_engagement_by_seniority()\n",
        "engagement_fig.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Key Insights for LinkedIn Post\n",
        "\n",
        "Summarizing the most compelling findings for your LinkedIn post.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate key insights for LinkedIn post\n",
        "def generate_linkedin_insights():\n",
        "    insights = {\n",
        "        'total_posts': len(df),\n",
        "        'total_companies': df['company'].nunique(),\n",
        "        'top_company': org_stats.index[0],\n",
        "        'top_company_engagement': org_stats['total_engagement'].iloc[0],\n",
        "        'most_active_level': seniority_stats['post_count'].idxmax(),\n",
        "        'highest_engaging_level': seniority_stats['avg_engagement'].idxmax(),\n",
        "        'top_topics': list(word_freq.items())[:5]\n",
        "    }\n",
        "    \n",
        "    # Calculate month-over-month growth\n",
        "    monthly_counts = df.groupby(df['post_date'].dt.to_period('M')).size()\n",
        "    if len(monthly_counts) >= 2:\n",
        "        mom_growth = ((monthly_counts.iloc[-1] - monthly_counts.iloc[-2]) / monthly_counts.iloc[-2] * 100).round(1)\n",
        "        insights['mom_growth'] = mom_growth\n",
        "    \n",
        "    return insights\n",
        "\n",
        "# Format insights for LinkedIn post\n",
        "def format_linkedin_post(insights):\n",
        "    post = f\"\"\"🔍 Who's Really Talking About AI in Kenya? Here's What I Found:\n",
        "\n",
        "After analyzing {insights['total_posts']} posts from {insights['total_companies']} leading organizations in Kenya, here are the key insights about AI and digital transformation discussions:\n",
        "\n",
        "🏢 Top Organizations:\n",
        "• {insights['top_company']} leads the conversation with highest engagement\n",
        "• {insights['most_active_level']}s are the most active in sharing AI insights\n",
        "• {insights['highest_engaging_level']}s generate the most engagement per post\n",
        "\n",
        "🔥 Hot Topics:\n",
        "\"\"\"\n",
        "    \n",
        "    # Add top topics\n",
        "    for topic, freq in insights['top_topics']:\n",
        "        post += f\"• {topic}\\n\"\n",
        "    \n",
        "    if 'mom_growth' in insights:\n",
        "        post += f\"\\n📈 The conversation is growing! {insights['mom_growth']}% increase in AI-related posts month-over-month.\\n\"\n",
        "    \n",
        "    post += \"\"\"\n",
        "💡 What This Means:\n",
        "The data shows Kenya's business landscape is actively embracing AI and digital transformation, with leaders across different organizational levels contributing to the conversation.\n",
        "\n",
        "#AIinKenya #DigitalTransformation #AfricanTech #Innovation #DataAnalysis\"\"\"\n",
        "    \n",
        "    return post\n",
        "\n",
        "# Generate and display LinkedIn post\n",
        "insights = generate_linkedin_insights()\n",
        "linkedin_post = format_linkedin_post(insights)\n",
        "print(\"Suggested LinkedIn Post:\")\n",
        "print(\"-\" * 80)\n",
        "print(linkedin_post)\n",
        "print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## 2. AI Discussion Trends and Topics\n",
        "\n",
        "Analyzing the most discussed AI topics and how they've evolved over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
